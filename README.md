# ğŸ›¡ï¸ Vigilix â€“ Intrusion Detection & Monitoring System

Welcome to **Vigilix**, an intelligent anomaly detection pipeline designed to identify and monitor network intrusions in real-time. This project leverages machine learning models, real-time data streaming, and monitoring tools to provide a robust and scalable solution for anomaly detection.

---

## ğŸ“š Overview

**Vigilix** is a modular and production-ready system that combines classical machine learning models with real-time monitoring capabilities. It is designed to process network data, detect anomalies, and visualize system performance metrics in real-time.

### Key Features:
- **Anomaly Detection Models:** Implements Isolation Forest, Random Forest, and XGBoost for anomaly detection.
- **Real-Time Data Streaming:** Uses Kafka for real-time data ingestion and processing.
- **Monitoring Stack:** Integrates Prometheus and Grafana for real-time metrics visualization.
- **Exploratory Data Analysis (EDA):** Provides insights into the dataset with statistical summaries and visualizations.
- **Preprocessing Utilities:** Includes scripts for data cleaning, transformation, and feature engineering.
- **Model Evaluation:** Tracks model performance with confusion matrices, feature importance, and evaluation metrics.
- **CI/CD Ready:** Compatible with CI/CD pipelines for automated testing and deployment.

---

## ğŸ–¼ï¸ System Architecture

### Network Intrusion Detection & Monitoring System Architecture
![System Architecture](results/images/System-Design.png)

This architecture illustrates the Vigilix pipeline:
1. **Data Ingestion:** Raw network data is ingested into Kafka topics.
2. **Data Processing:** Data is preprocessed and streamed to machine learning models for inference.
3. **Anomaly Detection:** Models classify data as normal or anomalous.
4. **Monitoring:** Prometheus collects metrics, and Grafana visualizes them in real-time dashboards.

---

## ğŸ–¥ï¸ Dashboard Example

### Vigilix Kafka Real-Time Monitoring Dashboard
![Dashboard Screenshot](results/images/Sample-Dashboard-Screenshot.png)

The dashboard provides real-time insights, including:
- Total network requests processed.
- Number of anomalies detected.
- Anomaly detection ratio.
- Model performance metrics (e.g., accuracy, precision, recall).

---

## ğŸ§­ Project Structure

```bash
atharsayed-vigilix/
â”œâ”€â”€ README.md                           # Project overview, setup guide, and usage documentation
â”œâ”€â”€ requirements.txt                    # Python dependencies for model, Kafka, and monitoring
â”œâ”€â”€ dockerfile                          # Docker build file for the Vigilix app service
â”œâ”€â”€ docker-compose.yml                  # Multi-service orchestration (App, Kafka, Zookeeper, Prometheus, Grafana)
â”œâ”€â”€ .gitignore                          # Excludes large datasets, build cache, logs, and system files
â”‚
â”œâ”€â”€ data/                               # (gitignored) Raw and processed datasets
â”‚   â”œâ”€â”€ raw/                            # Raw unprocessed data files (CSV, JSON, etc.)
â”‚   â””â”€â”€ processed/                      # Cleaned and split datasets for model training/testing (.parquet)
â”‚
â”œâ”€â”€ models/                             # ML model training, tuning, and inference scripts
â”‚   â”œâ”€â”€ app.py                          # Model evaluation entry point (train/test and log metrics)
â”‚   â”œâ”€â”€ hyper_xgb.py                    # Hyperparameter tuning script for XGBoost
â”‚   â”œâ”€â”€ isolation_forest.py             # Isolation Forest-based anomaly detection
â”‚   â”œâ”€â”€ random_forest.py                # Random Forest classification implementation
â”‚   â””â”€â”€ xgboost_model.py                # XGBoost model for classification/anomaly detection
â”‚
â”œâ”€â”€ monitoring/                         # Monitoring and observability setup for Vigilix
â”‚   â”œâ”€â”€ grafana/                        # Grafana dashboards and provisioning
â”‚   â”‚   â”œâ”€â”€ datasource.yaml             # Pre-configured Prometheus datasource for Grafana
â”‚   â”‚   â”œâ”€â”€ dashboards.yaml             # Dashboard auto-provisioning configuration
â”‚   â”‚   â””â”€â”€ vigilix_dashboard.json      # Custom Vigilix dashboard for live metrics visualization
â”‚   â”‚
â”‚   â”œâ”€â”€ prometheus/                     # Prometheus-specific configurations
â”‚   â”‚   â””â”€â”€ prometheus.yml              # Local Prometheus config for manual runs
â”‚   â”‚
â”‚   â””â”€â”€ prometheus.docker.yml           # Prometheus config for Docker environment (targets internal container names)
â”‚
â”œâ”€â”€ results/                            # Logs, visual outputs, and model performance reports
â”‚   â”œâ”€â”€ eda/                            # EDA (Exploratory Data Analysis) summaries
â”‚   â”‚   â””â”€â”€ eda_summary.txt             # Descriptive statistics and data insights summary
â”‚   â”‚
â”‚   â”œâ”€â”€ images/                         # Visual documentation (architecture diagrams, dashboards)
â”‚   â”‚   â”œâ”€â”€ Sample-Dashboard-Screenshot.png  # Snapshot of Grafana dashboard
â”‚   â”‚   â””â”€â”€ System-Design.png                # End-to-end Vigilix system architecture
â”‚   â”‚
â”‚   â””â”€â”€ models/                         # Model evaluation logs and result files
â”‚       â”œâ”€â”€ isolationforest_results.txt      # Isolation Forest results
â”‚       â”œâ”€â”€ RandomForest_results.txt         # Random Forest results
â”‚       â”œâ”€â”€ XGBoost_results.txt              # XGBoost baseline results
â”‚       â””â”€â”€ XGBoost_Tuned_results.txt        # XGBoost hyperparameter tuning results
â”‚
â”œâ”€â”€ scripts/                            # Automation and helper scripts for local environment setup
â”‚   â”œâ”€â”€ start-kafka.bat                 # Windows script to start Zookeeper & Kafka manually
â”‚   â””â”€â”€ start-prometheus.bat            # Windows script to start Prometheus manually   
â”‚
â”œâ”€â”€ src/                                # Core application logic and orchestration layer
â”‚   â”œâ”€â”€ main.py                         # ğŸ”¥ Main orchestrator â€” runs producer, consumer, model inference, and metrics
â”‚   â”œâ”€â”€ eda.py                          # Performs exploratory data analysis on raw/processed data
â”‚   â”œâ”€â”€ preprocess.py                   # Cleans, normalizes, and encodes raw data before training
â”‚   â””â”€â”€ utils.py                        # Shared helper functions (logging, Kafka utilities, config parsing)
â”‚
â”œâ”€â”€ streaming/                          # Kafka real-time data streaming modules
â”‚   â”œâ”€â”€ kafka_producer.py               # Producer that sends live data into Kafka topics
â”‚   â”œâ”€â”€ kafka_consumer.py               # Consumer that processes and scores streaming data
â”‚   â””â”€â”€ synthetic_producer.py           # Synthetic data generator for simulating real-time streams
â”‚
â””â”€â”€ testing/                            # Unit and integration tests for model and pipeline
   â””â”€â”€ test_app.py                     # Tests model inference and main orchestration logic

```

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.8 or higher
- Docker and Docker Compose
- Java Runtime Environment (for Kafka)

### Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/AtharSayed/vigilix.git
   cd vigilix
   ```

2. Build the Docker Image
   ```bash
   docker compose build --no-cache app
   ```

3. Start the Entire Stack:
   ```bash
   docker compose up -d
   ```

4. Verify Containers
   ```bash
   docker ps
   ```
- This launches all the services in the container.
---

| Service        | URL                                            | Description                                            |
| -----------    | ---------------------------------------------- | ------------------------------------------------------ |
| **Grafana**    | [http://localhost:3000](http://localhost:3000) | Visualization Dashboard (user: `admin`, pass: `admin`) |
| **Prometheus** | [http://localhost:9090](http://localhost:9090) | Metrics and targets                                    |
| **Kafka**      | `localhost:9094`                               | Kafka broker (accessible via internal `kafka:9092`)    |



## ğŸ› ï¸ Components

### 1. **Data Pipeline**
- **Kafka Producer:** Streams synthetic or real network data to Kafka topics.
- **Kafka Consumer:** Consumes data from Kafka topics and sends it to the ML models for inference.

### 2. **Machine Learning Models**
- **Isolation Forest:** Unsupervised anomaly detection model.
- **Random Forest:** Supervised classification model.
- **XGBoost:** Gradient boosting model for high-performance classification.

### 3. **Monitoring Stack**
- **Prometheus:** Collects metrics from the pipeline and models.
- **Grafana:** Visualizes metrics in real-time dashboards.

---

## ğŸ“Š Results

### Exploratory Data Analysis (EDA)
- **Correlation Heatmap:** Visualizes relationships between features.
- **Label Distribution:** Shows the distribution of normal vs. anomalous data.
- **Attack Category Distribution:** Highlights the types of attacks in the dataset.

### Model Evaluation
- **Confusion Matrices:** Evaluate model performance.
- **Feature Importance:** Identify the most important features for classification.
- **Metrics:** Accuracy, precision, recall, and F1-score.

---

## ğŸ§ª Testing

### Unit Tests
Run test_app.py to see the results of the prediction There are 2 attack and 2 non attack payloads hardcoded in the fiile that will be send to the model and in return the model will predict whether its an attack or not .
```bash
pytest testing/
```

---

## ğŸ›¡ï¸ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:
1. Fork the repository.
2. Create a new branch for your feature or bug fix.
3. Submit a pull request with a detailed description of your changes.

---


## ğŸŒŸ Acknowledgments

- **Kafka:** For real-time data streaming.
- **Prometheus & Grafana:** For monitoring and visualization.
- **Scikit-learn & XGBoost:** For machine learning models.
- **UNSW-NB15 Dataset:** For providing the dataset used in this project.
